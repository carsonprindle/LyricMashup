{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13944\n",
      "1446286\n"
     ]
    }
   ],
   "source": [
    "text= open(\"lyrics_kanye.txt\").read()\n",
    "chars = sorted(list(set(text.split(\" \")))) #split into a sorted list of characters\n",
    "text_list = text.split(\" \")\n",
    "text_list_size = len(text_list)\n",
    "vocab_size = len(chars)\n",
    "char_size = len(text) \n",
    "print(vocab_size)\n",
    "print(char_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ix_to_char = {ix:char for ix, char in enumerate(chars)} #create a dictionary of the spot of each character\n",
    "char_to_ix = {char:ix for ix, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  97223\n"
     ]
    }
   ],
   "source": [
    "#create number of sequences\n",
    "sequence_cap = 3 #want to make sure it doesn't overuse unique patterns\n",
    "#below to \"End pattern organization from: https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\"\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, text_list_size - sequence_cap, sequence_cap):\n",
    "\tseq_in = text_list[i:i + sequence_cap]\n",
    "\tseq_out = text_list[i + sequence_cap]\n",
    "\tdataX.append([char_to_ix[char] for char in seq_in])\n",
    "\tdataY.append(char_to_ix[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X =  np.reshape(dataX, (n_patterns, sequence_cap,1))\n",
    "# normalize\n",
    "X = X / float(vocab_size)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "#End pattern organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "97223/97223 [==============================] - 11s 110us/step - loss: 6.9200\n",
      "\n",
      "Epoch 00001: loss improved from inf to 6.92004, saving model to weights-improvement-01-6.9200.hdf5\n",
      "Epoch 2/20\n",
      "97223/97223 [==============================] - 9s 94us/step - loss: 6.6702\n",
      "\n",
      "Epoch 00002: loss improved from 6.92004 to 6.67016, saving model to weights-improvement-02-6.6702.hdf5\n",
      "Epoch 3/20\n",
      "97223/97223 [==============================] - 9s 89us/step - loss: 6.6542\n",
      "\n",
      "Epoch 00003: loss improved from 6.67016 to 6.65418, saving model to weights-improvement-03-6.6542.hdf5\n",
      "Epoch 4/20\n",
      "97223/97223 [==============================] - 9s 96us/step - loss: 6.6472\n",
      "\n",
      "Epoch 00004: loss improved from 6.65418 to 6.64717, saving model to weights-improvement-04-6.6472.hdf5\n",
      "Epoch 5/20\n",
      "97223/97223 [==============================] - 9s 90us/step - loss: 6.6371\n",
      "\n",
      "Epoch 00005: loss improved from 6.64717 to 6.63705, saving model to weights-improvement-05-6.6371.hdf5\n",
      "Epoch 6/20\n",
      "97223/97223 [==============================] - 9s 90us/step - loss: 6.6202\n",
      "\n",
      "Epoch 00006: loss improved from 6.63705 to 6.62019, saving model to weights-improvement-06-6.6202.hdf5\n",
      "Epoch 7/20\n",
      "97223/97223 [==============================] - 9s 90us/step - loss: 6.5985\n",
      "\n",
      "Epoch 00007: loss improved from 6.62019 to 6.59853, saving model to weights-improvement-07-6.5985.hdf5\n",
      "Epoch 8/20\n",
      "97223/97223 [==============================] - 9s 88us/step - loss: 6.5724\n",
      "\n",
      "Epoch 00008: loss improved from 6.59853 to 6.57241, saving model to weights-improvement-08-6.5724.hdf5\n",
      "Epoch 9/20\n",
      "97223/97223 [==============================] - 9s 92us/step - loss: 6.5464\n",
      "\n",
      "Epoch 00009: loss improved from 6.57241 to 6.54644, saving model to weights-improvement-09-6.5464.hdf5\n",
      "Epoch 10/20\n",
      "97223/97223 [==============================] - 9s 93us/step - loss: 6.5185\n",
      "\n",
      "Epoch 00010: loss improved from 6.54644 to 6.51845, saving model to weights-improvement-10-6.5185.hdf5\n",
      "Epoch 11/20\n",
      "97223/97223 [==============================] - 9s 88us/step - loss: 6.4901\n",
      "\n",
      "Epoch 00011: loss improved from 6.51845 to 6.49013, saving model to weights-improvement-11-6.4901.hdf5\n",
      "Epoch 12/20\n",
      "97223/97223 [==============================] - 9s 91us/step - loss: 6.4619\n",
      "\n",
      "Epoch 00012: loss improved from 6.49013 to 6.46190, saving model to weights-improvement-12-6.4619.hdf5\n",
      "Epoch 13/20\n",
      "97223/97223 [==============================] - 9s 90us/step - loss: 6.4337\n",
      "\n",
      "Epoch 00013: loss improved from 6.46190 to 6.43373, saving model to weights-improvement-13-6.4337.hdf5\n",
      "Epoch 14/20\n",
      "97223/97223 [==============================] - 9s 88us/step - loss: 6.4044\n",
      "\n",
      "Epoch 00014: loss improved from 6.43373 to 6.40443, saving model to weights-improvement-14-6.4044.hdf5\n",
      "Epoch 15/20\n",
      "97223/97223 [==============================] - 8s 86us/step - loss: 6.3736\n",
      "\n",
      "Epoch 00015: loss improved from 6.40443 to 6.37363, saving model to weights-improvement-15-6.3736.hdf5\n",
      "Epoch 16/20\n",
      "97223/97223 [==============================] - 9s 88us/step - loss: 6.3422\n",
      "\n",
      "Epoch 00016: loss improved from 6.37363 to 6.34224, saving model to weights-improvement-16-6.3422.hdf5\n",
      "Epoch 17/20\n",
      "97223/97223 [==============================] - 8s 87us/step - loss: 6.3103\n",
      "\n",
      "Epoch 00017: loss improved from 6.34224 to 6.31027, saving model to weights-improvement-17-6.3103.hdf5\n",
      "Epoch 18/20\n",
      "97223/97223 [==============================] - 9s 91us/step - loss: 6.2788\n",
      "\n",
      "Epoch 00018: loss improved from 6.31027 to 6.27880, saving model to weights-improvement-18-6.2788.hdf5\n",
      "Epoch 19/20\n",
      "97223/97223 [==============================] - 9s 90us/step - loss: 6.2445\n",
      "\n",
      "Epoch 00019: loss improved from 6.27880 to 6.24449, saving model to weights-improvement-19-6.2445.hdf5\n",
      "Epoch 20/20\n",
      "97223/97223 [==============================] - 9s 90us/step - loss: 6.2112\n",
      "\n",
      "Epoch 00020: loss improved from 6.24449 to 6.21123, saving model to weights-improvement-20-6.2112.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a3c0acc88>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from machinelearning site above.....\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# fit the model\n",
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" problems---of---my \"\n"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", '---'.join([ix_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a and p must have same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-48d76ad78dd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mp_bettah\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp_better\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#index = np.argmax(prediction)#maybe not most likely\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_cap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#this is now the list of next 3 words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#index = np.random.choice(prediction, size=None, replace=True, p=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#result = ix_to_char[index]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a and p must have same size"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(vocab_size)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    p_better=[prediction[0]]\n",
    "    p_bettah=[p_better[0]]\n",
    "    #index = np.argmax(prediction)#maybe not most likely \n",
    "    index = np.random.choice(chars, size=sequence_cap, p=prediction[0]) #this is now the list of next 3 words\n",
    "    #index = np.random.choice(prediction, size=None, replace=True, p=None)\n",
    "    #result = ix_to_char[index]\n",
    "    #seq_in = [ix_to_char[value] for value in pattern]\n",
    "    #print(index)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")\n",
    "print(vocab_size) \n",
    "print(len(p_bettah))\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'zip' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-d04225339b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mheapq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtop_ten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mheapq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_ten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'zip' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import operator\n",
    "top_ten = zip(*heapq.nlargest(10, enumerate(prediction), key=operator.itemgetter(1)))[0]\n",
    "print(top_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as pr\n",
    "\n",
    "def rargmax(vector):\n",
    "    \"\"\" Argmax that chooses randomly among eligible maximum indices. \"\"\"\n",
    "    m = np.amax(vector)\n",
    "    indices = np.nonzero(vector == m)[0]\n",
    "    return pr.choice(indices)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test = [0,1,2,2]\n",
    "    for i in range(10):\n",
    "        print(rargmax(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiitheiithei\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(vocab_size)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = np.argmax(prediction)\n",
    "\tresult = ix_to_char[index]\n",
    "\tseq_in = [ix_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
